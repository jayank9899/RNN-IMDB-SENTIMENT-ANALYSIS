{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547e8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f73e0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[320, 92, 27, 544],\n",
       " [320, 92, 27, 435],\n",
       " [320, 665, 27, 709],\n",
       " [146, 11, 927, 962, 651],\n",
       " [146, 11, 927, 962, 990],\n",
       " [591, 320, 454, 27, 180],\n",
       " [388, 945, 109, 962]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "voc_size=1000\n",
    "\n",
    "one_hot_repr=[one_hot(words,voc_size) for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf41a",
   "metadata": {},
   "source": [
    "The one_hot function from Keras does not create a full one-hot vector for each word. Instead, it assigns a unique integer index (from 1 to voc_size) to each word in your sentences. So, each word is represented by a single number, not a full vector.\n",
    "\n",
    "Why?\n",
    "\n",
    "This is called \"integer encoding\" or \"tokenization,\" not true one-hot encoding.\n",
    "It's more memory-efficient: instead of storing a long vector of mostly zeros for each word, you just store its index.\n",
    "The actual one-hot vector (with 1 at the index and 0 elsewhere) is created later, usually inside the embedding layer of your neural network.\n",
    "Summary:\n",
    "\n",
    "one_hot(words, voc_size) → returns a list of integers (word indices).\n",
    "True one-hot vectors are not created at this step; they are created on-the-fly if needed, or more commonly, the indices are passed to an embedding layer.\n",
    "Let me know if you want to see how to create true one-hot vectors or how embeddings work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word Embedding Representation\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d07c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0 320  92  27 544]\n",
      " [  0   0   0   0 320  92  27 435]\n",
      " [  0   0   0   0 320 665  27 709]\n",
      " [  0   0   0 146  11 927 962 651]\n",
      " [  0   0   0 146  11 927 962 990]\n",
      " [  0   0   0 591 320 454  27 180]\n",
      " [  0   0   0   0 388 945 109 962]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=8\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec6073",
   "metadata": {},
   "source": [
    "### What is pad_sequences and why is it used?\n",
    "- Neural networks expect input data to have the same shape (length).\n",
    "- In NLP, sentences have different numbers of words, so their integer-encoded representations have different lengths.\n",
    "- `pad_sequences` is used to make all sequences the same length by adding zeros (or another value) at the beginning or end.\n",
    "- This allows you to batch sentences together and feed them into the model efficiently.\n",
    "- Example usage:\n",
    "```python\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "sent_length = 8\n",
    "embedded_docs = pad_sequences(one_hot_repr, padding='pre', maxlen=sent_length)\n",
    "print(embedded_docs)\n",
    "```\n",
    "- Here, all sentences are padded to length 8, so the input to the model is a consistent shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0884642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "dim =10 \n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim))\n",
    "model.compile('adam','mse')\n",
    "model.build(input_shape=(None, sent_length))\n",
    "\n",
    "print(voc_size)\n",
    "print(dim)\n",
    "print(sent_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63a763",
   "metadata": {},
   "source": [
    "### Explanation of Embedding Layer Parameters and Data Shape\n",
    "- **voc_size**: The size of your vocabulary (total number of unique words you want to represent). Each word index from 1 to voc_size will have its own embedding vector.\n",
    "    - Example: If voc_size=1000, the embedding layer can represent 1000 different words.\n",
    "- **dim**: The dimension of the embedding vector for each word. This is how many numbers represent each word in the embedding space.\n",
    "    - Example: If dim=10, each word is represented by a 10-dimensional vector (e.g., [0.12, -0.34, ..., 0.56]).\n",
    "- **sent_length**: The length to which all input sequences (sentences) are padded or truncated. This ensures all input data has the same shape for batching.\n",
    "    - Example: If sent_length=8, every sentence is represented as a sequence of 8 word indices (padded with zeros if shorter).\n",
    "\n",
    "#### How does the data look?\n",
    "- Before embedding: Each sentence is a list of integers (word indices), all padded to length `sent_length`.\n",
    "    - Example: `[0, 0, 0, 0, 12, 45, 23, 67]` (if the sentence had 4 words, padded to 8)\n",
    "- After embedding: Each integer is replaced by a vector of length `dim`. So, each sentence becomes a matrix of shape `(sent_length, dim)`.\n",
    "    - Example:\n",
    "        - Input: `[0, 0, 0, 0, 12, 45, 23, 67]`\n",
    "        - Output:\n",
    "            ```\n",
    "            [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             [0.12, -0.34, ..., 0.56],\n",
    "             [0.22, 0.11, ..., -0.09],\n",
    "             [0.05, 0.18, ..., 0.33],\n",
    "             [-0.12, 0.44, ..., 0.21]]\n",
    "            ```\n",
    "- The output shape from the embedding layer is `(batch_size, sent_length, dim)`.\n",
    "- This format is ready for input to RNN, LSTM, or other sequence models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b861cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │        \u001b[38;5;34m10,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,000</span> (39.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,000\u001b[0m (39.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,000</span> (39.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,000\u001b[0m (39.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b11609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [ 2.17866041e-02, -2.10267790e-02, -5.89563698e-03,\n",
       "          3.59113477e-02, -1.44238099e-02,  2.82112025e-02,\n",
       "          4.78067137e-02,  1.81851424e-02, -1.14085451e-02,\n",
       "          2.88557261e-04],\n",
       "        [-4.98784296e-02, -2.05776338e-02,  3.68870609e-02,\n",
       "          1.77055635e-02, -2.86918413e-02,  1.04229935e-02,\n",
       "          7.99819827e-06, -2.14360487e-02, -1.78166404e-02,\n",
       "          4.31322344e-02],\n",
       "        [ 1.26905926e-02, -1.60837062e-02,  1.44130103e-02,\n",
       "          3.28826644e-02, -4.52496521e-02,  2.92987712e-02,\n",
       "          3.09390537e-02,  2.72138752e-02,  2.60635279e-02,\n",
       "          4.98797633e-02],\n",
       "        [-4.98920344e-02, -1.57142505e-02, -4.26357277e-02,\n",
       "          5.14381006e-03, -4.10408862e-02, -5.13060018e-03,\n",
       "         -3.93376462e-02, -6.86769560e-03,  1.13759041e-02,\n",
       "         -4.33634780e-02]],\n",
       "\n",
       "       [[-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [ 2.17866041e-02, -2.10267790e-02, -5.89563698e-03,\n",
       "          3.59113477e-02, -1.44238099e-02,  2.82112025e-02,\n",
       "          4.78067137e-02,  1.81851424e-02, -1.14085451e-02,\n",
       "          2.88557261e-04],\n",
       "        [-4.98784296e-02, -2.05776338e-02,  3.68870609e-02,\n",
       "          1.77055635e-02, -2.86918413e-02,  1.04229935e-02,\n",
       "          7.99819827e-06, -2.14360487e-02, -1.78166404e-02,\n",
       "          4.31322344e-02],\n",
       "        [ 1.26905926e-02, -1.60837062e-02,  1.44130103e-02,\n",
       "          3.28826644e-02, -4.52496521e-02,  2.92987712e-02,\n",
       "          3.09390537e-02,  2.72138752e-02,  2.60635279e-02,\n",
       "          4.98797633e-02],\n",
       "        [ 4.70861085e-02,  3.59240063e-02, -3.03313881e-03,\n",
       "         -2.91290414e-02, -3.98293249e-02,  3.22798155e-02,\n",
       "          9.01355594e-03, -1.75343864e-02,  2.53327154e-02,\n",
       "         -9.23893601e-03]],\n",
       "\n",
       "       [[-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [ 2.17866041e-02, -2.10267790e-02, -5.89563698e-03,\n",
       "          3.59113477e-02, -1.44238099e-02,  2.82112025e-02,\n",
       "          4.78067137e-02,  1.81851424e-02, -1.14085451e-02,\n",
       "          2.88557261e-04],\n",
       "        [-3.19475681e-02, -2.69971136e-02, -3.57266515e-03,\n",
       "          1.74522512e-02, -5.55967167e-03,  4.10855450e-02,\n",
       "         -1.67539604e-02, -3.65805142e-02, -1.90531015e-02,\n",
       "         -4.58780900e-02],\n",
       "        [ 1.26905926e-02, -1.60837062e-02,  1.44130103e-02,\n",
       "          3.28826644e-02, -4.52496521e-02,  2.92987712e-02,\n",
       "          3.09390537e-02,  2.72138752e-02,  2.60635279e-02,\n",
       "          4.98797633e-02],\n",
       "        [ 3.66630815e-02, -2.74321679e-02,  1.66686513e-02,\n",
       "         -3.14499512e-02, -1.23737007e-03, -2.67831814e-02,\n",
       "         -3.20927054e-03,  3.78244631e-02, -2.03565005e-02,\n",
       "         -3.02100070e-02]],\n",
       "\n",
       "       [[-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-4.04306538e-02, -2.52947565e-02,  1.58768632e-02,\n",
       "          4.95079271e-02, -2.51942761e-02,  7.24260882e-03,\n",
       "          2.25805156e-02, -4.35302146e-02,  1.69497989e-02,\n",
       "         -3.45769897e-02],\n",
       "        [-4.72396612e-03, -4.50841561e-02, -1.30854249e-02,\n",
       "         -2.11982019e-02,  3.54434587e-02,  2.06853859e-02,\n",
       "          4.01894115e-02,  2.96284221e-02,  2.75094025e-02,\n",
       "          4.08705808e-02],\n",
       "        [-3.01924348e-02,  3.80679704e-02,  2.52185501e-02,\n",
       "          6.08683750e-03, -1.09961256e-02,  2.17233412e-02,\n",
       "         -4.11375053e-02,  1.42505430e-02, -4.67852354e-02,\n",
       "          4.17220332e-02],\n",
       "        [ 3.73621918e-02, -4.21812385e-03, -3.27228904e-02,\n",
       "          3.91616561e-02,  1.57236718e-02,  2.68893354e-02,\n",
       "         -4.52732816e-02,  3.97517346e-02, -9.48580354e-03,\n",
       "          4.11824845e-02],\n",
       "        [-4.35332917e-02,  6.09178469e-03,  3.49432230e-06,\n",
       "          2.76856460e-02,  9.80461761e-03, -1.60660520e-02,\n",
       "         -7.01186806e-03,  7.67551735e-03, -3.01021822e-02,\n",
       "          3.41558196e-02]],\n",
       "\n",
       "       [[-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-4.04306538e-02, -2.52947565e-02,  1.58768632e-02,\n",
       "          4.95079271e-02, -2.51942761e-02,  7.24260882e-03,\n",
       "          2.25805156e-02, -4.35302146e-02,  1.69497989e-02,\n",
       "         -3.45769897e-02],\n",
       "        [-4.72396612e-03, -4.50841561e-02, -1.30854249e-02,\n",
       "         -2.11982019e-02,  3.54434587e-02,  2.06853859e-02,\n",
       "          4.01894115e-02,  2.96284221e-02,  2.75094025e-02,\n",
       "          4.08705808e-02],\n",
       "        [-3.01924348e-02,  3.80679704e-02,  2.52185501e-02,\n",
       "          6.08683750e-03, -1.09961256e-02,  2.17233412e-02,\n",
       "         -4.11375053e-02,  1.42505430e-02, -4.67852354e-02,\n",
       "          4.17220332e-02],\n",
       "        [ 3.73621918e-02, -4.21812385e-03, -3.27228904e-02,\n",
       "          3.91616561e-02,  1.57236718e-02,  2.68893354e-02,\n",
       "         -4.52732816e-02,  3.97517346e-02, -9.48580354e-03,\n",
       "          4.11824845e-02],\n",
       "        [-2.70104762e-02, -1.68587342e-02,  3.11417505e-03,\n",
       "         -4.85686325e-02,  6.75152615e-03, -3.01120412e-02,\n",
       "         -3.15141901e-02,  1.12358481e-03, -4.23945487e-04,\n",
       "         -3.49667892e-02]],\n",
       "\n",
       "       [[-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [ 1.50473379e-02, -4.34444100e-03,  2.75513195e-02,\n",
       "          3.30521204e-02, -2.70577203e-02,  1.27819665e-02,\n",
       "          1.84173249e-02, -4.94534150e-02, -5.55449724e-03,\n",
       "         -4.32246588e-02],\n",
       "        [ 2.17866041e-02, -2.10267790e-02, -5.89563698e-03,\n",
       "          3.59113477e-02, -1.44238099e-02,  2.82112025e-02,\n",
       "          4.78067137e-02,  1.81851424e-02, -1.14085451e-02,\n",
       "          2.88557261e-04],\n",
       "        [-3.68480198e-02, -3.08007952e-02, -1.48106217e-02,\n",
       "         -1.71185248e-02,  6.59720972e-03, -3.64828110e-03,\n",
       "          4.18139733e-02, -3.90769616e-02, -7.35416263e-03,\n",
       "          3.72385047e-02],\n",
       "        [ 1.26905926e-02, -1.60837062e-02,  1.44130103e-02,\n",
       "          3.28826644e-02, -4.52496521e-02,  2.92987712e-02,\n",
       "          3.09390537e-02,  2.72138752e-02,  2.60635279e-02,\n",
       "          4.98797633e-02],\n",
       "        [-6.49738312e-03,  4.98094298e-02, -7.97152519e-03,\n",
       "          1.08178705e-03, -2.52918005e-02, -3.56324688e-02,\n",
       "         -1.91755183e-02,  1.55229606e-02,  1.55502558e-03,\n",
       "          1.51807778e-02]],\n",
       "\n",
       "       [[-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-8.77772644e-03,  3.36878560e-02, -2.94252522e-02,\n",
       "         -4.00644056e-02,  2.90828608e-02,  6.52499124e-03,\n",
       "         -4.72992063e-02,  4.38555814e-02,  1.96745731e-02,\n",
       "         -2.31575612e-02],\n",
       "        [-3.90510336e-02,  5.15496731e-03,  1.02368221e-02,\n",
       "          3.95258106e-02,  3.48810442e-02,  1.86085962e-02,\n",
       "          2.78915800e-02, -1.60151497e-02,  2.54411586e-02,\n",
       "         -4.85559218e-02],\n",
       "        [-1.36894360e-02,  3.67866419e-02, -7.46179372e-04,\n",
       "          4.44275402e-02, -3.66770253e-02,  2.29508393e-02,\n",
       "         -2.97728311e-02, -4.88563664e-02,  4.83712591e-02,\n",
       "          4.44679521e-02],\n",
       "        [ 3.80320810e-02,  8.56927782e-03, -3.44670899e-02,\n",
       "         -4.41545956e-02,  3.84699963e-02, -2.58600246e-02,\n",
       "         -1.92928445e-02,  3.23424488e-03, -1.66010261e-02,\n",
       "          6.76629692e-03],\n",
       "        [ 3.73621918e-02, -4.21812385e-03, -3.27228904e-02,\n",
       "          3.91616561e-02,  1.57236718e-02,  2.68893354e-02,\n",
       "         -4.52732816e-02,  3.97517346e-02, -9.48580354e-03,\n",
       "          4.11824845e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb9d15",
   "metadata": {},
   "source": [
    "### Interpreting the Output of `model.predict(embedded_docs)`\n",
    "\n",
    "- The output of this cell is a **3D numpy array** with shape `(number of sentences, sent_length, dim)`.\n",
    "    - In this example: `(7, 8, 10)` because there are 7 sentences, each padded to length 8, and each word is represented by a 10-dimensional embedding vector.\n",
    "\n",
    "- **What does each number mean?**\n",
    "    - For each sentence, for each word position (including padding), you get a vector of length 10.\n",
    "    - The values are floating-point numbers. They are the learned (or randomly initialized, if not trained) embedding values for each word index.\n",
    "\n",
    "- **Example:**\n",
    "    - For the first sentence, the output might look like:\n",
    "        ```\n",
    "        [[ 0.01, -0.02, ..., 0.03],   # padding (index 0)\n",
    "         [ 0.01, -0.02, ..., 0.03],   # padding (index 0)\n",
    "         ...\n",
    "         [ 0.12, 0.45, ..., -0.11],   # word 1\n",
    "         [ 0.22, -0.15, ..., 0.09],   # word 2\n",
    "         ... ]\n",
    "        ```\n",
    "\n",
    "- **Padding positions** (where the input was 0) will have the embedding for index 0, which is usually a vector of zeros or small random values.\n",
    "\n",
    "- **Why is this useful?**\n",
    "    - The embedding layer transforms each word index into a dense vector that captures semantic meaning.\n",
    "    - The output is ready to be fed into further layers like RNN, LSTM, or CNN for sequence modeling.\n",
    "\n",
    "- **Summary Table:**\n",
    "\n",
    "| Dimension         | Meaning                                 |\n",
    "|-------------------|-----------------------------------------|\n",
    "| 1st (axis 0)      | Sentence index (batch)                  |\n",
    "| 2nd (axis 1)      | Word position in the sentence           |\n",
    "| 3rd (axis 2)      | Embedding vector for each word (length=dim) |\n",
    "\n",
    "- You can inspect the shape with:\n",
    "```python\n",
    "output = model.predict(embedded_docs)\n",
    "print(output.shape)  # (7, 8, 10)\n",
    "```\n",
    "\n",
    "Let me know if you want to see how to visualize or further process these embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa023be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "(7, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(embedded_docs)\n",
    "print(output.shape)  # (7, 8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f1c6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 320,  92,  27, 544], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01a6a454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.7777264e-03,  3.3687856e-02, -2.9425252e-02, -4.0064406e-02,\n",
       "         2.9082861e-02,  6.5249912e-03, -4.7299206e-02,  4.3855581e-02,\n",
       "         1.9674573e-02, -2.3157561e-02],\n",
       "       [-8.7777264e-03,  3.3687856e-02, -2.9425252e-02, -4.0064406e-02,\n",
       "         2.9082861e-02,  6.5249912e-03, -4.7299206e-02,  4.3855581e-02,\n",
       "         1.9674573e-02, -2.3157561e-02],\n",
       "       [-8.7777264e-03,  3.3687856e-02, -2.9425252e-02, -4.0064406e-02,\n",
       "         2.9082861e-02,  6.5249912e-03, -4.7299206e-02,  4.3855581e-02,\n",
       "         1.9674573e-02, -2.3157561e-02],\n",
       "       [-8.7777264e-03,  3.3687856e-02, -2.9425252e-02, -4.0064406e-02,\n",
       "         2.9082861e-02,  6.5249912e-03, -4.7299206e-02,  4.3855581e-02,\n",
       "         1.9674573e-02, -2.3157561e-02],\n",
       "       [ 2.1786604e-02, -2.1026779e-02, -5.8956370e-03,  3.5911348e-02,\n",
       "        -1.4423810e-02,  2.8211202e-02,  4.7806714e-02,  1.8185142e-02,\n",
       "        -1.1408545e-02,  2.8855726e-04],\n",
       "       [-4.9878430e-02, -2.0577634e-02,  3.6887061e-02,  1.7705563e-02,\n",
       "        -2.8691841e-02,  1.0422993e-02,  7.9981983e-06, -2.1436049e-02,\n",
       "        -1.7816640e-02,  4.3132234e-02],\n",
       "       [ 1.2690593e-02, -1.6083706e-02,  1.4413010e-02,  3.2882664e-02,\n",
       "        -4.5249652e-02,  2.9298771e-02,  3.0939054e-02,  2.7213875e-02,\n",
       "         2.6063528e-02,  4.9879763e-02],\n",
       "       [-4.9892034e-02, -1.5714251e-02, -4.2635728e-02,  5.1438101e-03,\n",
       "        -4.1040886e-02, -5.1306002e-03, -3.9337646e-02, -6.8676956e-03,\n",
       "         1.1375904e-02, -4.3363478e-02]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0] # Output for the first sentence [  0,   0,   0,   0, 677, 911, 388, 953]\n",
    "# why 8 lists? because 8 words, each word converted to a 10-dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8798dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00877773,  0.03368786, -0.02942525, -0.04006441,  0.02908286,\n",
       "        0.00652499, -0.04729921,  0.04385558,  0.01967457, -0.02315756],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0] #  # Output for the first word in the first sentence\n",
    "# why length 10 ? because dim is 10 in the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60eaf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da5896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_neuralnetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
